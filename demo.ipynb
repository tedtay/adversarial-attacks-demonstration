{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4481503e-9095-44a2-97f5-4fd0337bc342",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca02f20-465f-465f-8d7d-738201e3467c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size : (1200, 1057)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "our_banana_raw = Image.open('/Users/ted.taylor/Downloads/ban.jpg')\n",
    "print(f\"Original size : {our_banana_raw.size}\") # 5464x3640\n",
    "\n",
    "our_banana = our_banana_raw.resize((256, 256))\n",
    "\n",
    "white_image = our_banana_raw.resize((256, 256))\n",
    "for i in range(0,255):\n",
    "    for j in range(0,255):\n",
    "        white_image.load()[i,j] = (255,255,255)\n",
    "black_image = our_banana_raw.resize((256, 256))\n",
    "for i in range(0,255):\n",
    "    for j in range(0,255):\n",
    "        black_image.load()[i,j] = (0,0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b936c48-8b89-4166-bdee-aaf05db88b0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/ted.taylor/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/ted.taylor/opt/anaconda3/envs/envAltair/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ted.taylor/opt/anaconda3/envs/envAltair/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from image import Image, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f54895-e8d3-48eb-8694-c556efa123b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "im = Image(our_banana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5433b01a-9917-4e22-b794-d15d50adb934",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(im.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f09552-7c32-4a06-a134-6ebb421fea72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image.Image"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cce7bc1-80f1-4786-8a1e-2c798e38c4be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change no.236\n",
      "old n_sub1_value: 94.78070831298828\n",
      "new n_sub1_value: 95.03263854980469\n",
      "Finished - After 237 changes\n"
     ]
    }
   ],
   "source": [
    "result =  im.trick99('lemon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa96450-ba29-4384-a7a9-81146c06ea4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d2e8d-5196-4a0e-b36f-285367d6ae2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90289ed7-d7f8-4fa0-a22a-31d34572c73d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec99a57-5fda-4386-9728-3e4e7dc5719e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81355ef2-926b-4798-ba99-d19a1e46492a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef009927-3ddb-45af-b135-26cacf8664b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edb706-3691-458e-b07b-34518922a16f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3077a6d7-18b2-41f1-a8c4-8c966a6b8db9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "object -> image\n",
    "attributes - pixel vals\n",
    "           - size\n",
    "methods:\n",
    "    resize(what x, y)\n",
    "    predict()\n",
    "    1-pixel-fool(what %)\n",
    "    palce-pixel(color, location)\n",
    "    place-circle(color, location, size)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352623aa-42a5-4f35-9037-2584a8810941",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03f0845-80ed-46e1-bdb7-745ffd92ad2c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imageResize(image_param):\n",
    "    \n",
    "    from torchvision import transforms\n",
    "    #\n",
    "    # Create a preprocessing pipeline\n",
    "    #\n",
    "    preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )])\n",
    "    #\n",
    "    # Pass the image for preprocessing and the image preprocessed\n",
    "    #\n",
    "    img_cat_preprocessed = preprocess(image_param)\n",
    "    return img_cat_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c156fc-e245-43b7-bd6d-a69fbb520e64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pred(image_param):\n",
    "    img_cat_preprocessed = imageResize(image_param)\n",
    "    #\n",
    "    # Reshape, crop, and normalize the input tensor for feeding into network for evaluation\n",
    "    #\n",
    "    batch_img_cat_tensor = torch.unsqueeze(img_cat_preprocessed, 0)\n",
    "\n",
    "    model.eval()\n",
    "    #\n",
    "    # Get the predictions of image as scores related to how the loaded image\n",
    "    # matches with 1000 ImageNet classes. The variable, out is a vector of 1000 scores\n",
    "    #\n",
    "    out = model(batch_img_cat_tensor)\n",
    "\n",
    "    # Load the file containing the 1,000 labels for the ImageNet dataset classes\n",
    "    #\n",
    "    with open('/Users/ted.taylor/Downloads/imagenet_classes.txt') as f:\n",
    "        labels = [line.strip() for line in f.readlines()]\n",
    "    #\n",
    "    # Find the index (tensor) corresponding to the maximum score in the out tensor.\n",
    "    # Torch.max function can be used to find the information\n",
    "    #\n",
    "    _, index = torch.max(out, 1)\n",
    "    #\n",
    "    # Find the score in terms of percentage by using torch.nn.functional.softmax function\n",
    "    # which normalizes the output to range [0,1] and multiplying by 100\n",
    "    #\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    #\n",
    "    # Print the name along with score of the object identified by the model\n",
    "    #\n",
    "    #print(labels[index[0]], percentage[index[0]].item())\n",
    "    #\n",
    "    # Print the top 5 scores along with the image label. Sort function is invoked on the torch to sort the scores.\n",
    "    #\n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    preds = [(labels[idx], percentage[idx].item()) for idx in indices[0][:]]\n",
    "    \n",
    "    return (preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e98a77-5408-4aef-af65-be942a00f8a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def trick99(image_param, name_param):\n",
    "    \n",
    "    name = name_param\n",
    "    run_image = image_param.resize((256, 256))\n",
    "    n_sub1_pred = pred(run_image)\n",
    "    n_sub1_value = [item for item in n_sub1_pred if item[0] == name][0][1]\n",
    "    k=0\n",
    "    while (n_sub1_pred[0][0] != name) or (n_sub1_pred[0][1] < 90):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        x_rand = random.randint(0, 255)\n",
    "        y_rand = random.randint(0, 255)\n",
    "\n",
    "        r_rand = random.randint(0, 255)\n",
    "        g_rand = random.randint(0, 255)\n",
    "        b_rand = random.randint(0, 255)\n",
    "\n",
    "        old_pixel_val = run_image.load()[x_rand,y_rand]\n",
    "        new_pixel_val = (r_rand,g_rand,b_rand)\n",
    "\n",
    "        run_image.load()[x_rand,y_rand] = (r_rand,g_rand,b_rand)\n",
    "        current_pred = pred(run_image)\n",
    "        current_value = [item for item in current_pred if item[0] == name][0][1]\n",
    "\n",
    "        if current_value > n_sub1_value:\n",
    "            print(f\"change no.{k}\")\n",
    "            print(f\"old n_sub1_value: {n_sub1_value}\")\n",
    "            #print(f\"BETTER ({x_rand},{y_rand}) old: {old_pixel_val}  new: {new_pixel_val}\")\n",
    "            n_sub1_pred = current_pred\n",
    "            n_sub1_value = current_value\n",
    "\n",
    "            print(f\"new n_sub1_value: {n_sub1_value}\")\n",
    "            k=k+1\n",
    "        else:\n",
    "            run_image.load()[x_rand,y_rand] = old_pixel_val\n",
    "            #print(f\"WORSE ({x_rand},{y_rand}) old: {old_pixel_val}  new: {new_pixel_val}\")\n",
    "\n",
    "    print(f'Finished - After {k} changes')\n",
    "    return ([pred(image_param.resize((256, 256))),pred(run_image),run_image])\n",
    "\n",
    "def trick(image_param, name_param):\n",
    "    \n",
    "    name = name_param\n",
    "    run_image = image_param.resize((256, 256))\n",
    "    n_sub1_pred = pred(run_image)\n",
    "    n_sub1_value = [item for item in n_sub1_pred if item[0] == name][0][1]\n",
    "    k=0\n",
    "    while n_sub1_pred[0][0] != name:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        x_rand = random.randint(0, 255)\n",
    "        y_rand = random.randint(0, 255)\n",
    "\n",
    "        r_rand = random.randint(0, 255)\n",
    "        g_rand = random.randint(0, 255)\n",
    "        b_rand = random.randint(0, 255)\n",
    "\n",
    "        old_pixel_val = run_image.load()[x_rand,y_rand]\n",
    "        new_pixel_val = (r_rand,g_rand,b_rand)\n",
    "\n",
    "        run_image.load()[x_rand,y_rand] = (r_rand,g_rand,b_rand)\n",
    "        current_pred = pred(run_image)\n",
    "        current_value = [item for item in current_pred if item[0] == name][0][1]\n",
    "\n",
    "        if current_value > n_sub1_value:\n",
    "            print(f\"change no.{k}\")\n",
    "            print(f\"old n_sub1_value: {n_sub1_value}\")\n",
    "            #print(f\"BETTER ({x_rand},{y_rand}) old: {old_pixel_val}  new: {new_pixel_val}\")\n",
    "            n_sub1_pred = current_pred\n",
    "            n_sub1_value = current_value\n",
    "\n",
    "            print(f\"new n_sub1_value: {n_sub1_value}\")\n",
    "            k=k+1\n",
    "        else:\n",
    "            run_image.load()[x_rand,y_rand] = old_pixel_val\n",
    "            #print(f\"WORSE ({x_rand},{y_rand}) old: {old_pixel_val}  new: {new_pixel_val}\")\n",
    "\n",
    "    print(f'Finished - After {k} changes')\n",
    "    return ([pred(image_param.resize((256, 256))),pred(run_image),run_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f15dc-dd9d-409f-97bd-629e332da8e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9f4a1-f597-4160-b756-a3d4a12e3188",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a01d65-3779-45c6-a825-a39c73639633",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfbe73-4aad-4ccc-b9d6-11822eba1de1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a62b0f-1188-40d4-b7f3-b51c5e0ae6a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result = trick(og_image.resize((256, 256)),'eggnog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a993f81-9562-409c-b89f-a3147012370d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6g/2n3nygvn62n8whycy0zpm7fmsw_mfq/T/ipykernel_79675/1631627183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwhite99\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwhite_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrick99\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhite99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hourglass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/6g/2n3nygvn62n8whycy0zpm7fmsw_mfq/T/ipykernel_79675/1396186416.py\u001b[0m in \u001b[0;36mtrick99\u001b[0;34m(image_param, name_param)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mrun_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_rand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_rand\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr_rand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_rand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_rand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcurrent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcurrent_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_pred\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6g/2n3nygvn62n8whycy0zpm7fmsw_mfq/T/ipykernel_79675/419890800.py\u001b[0m in \u001b[0;36mpred\u001b[0;34m(image_param)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# matches with 1000 ImageNet classes. The variable, out is a vector of 1000 scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img_cat_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Load the file containing the 1,000 labels for the ImageNet dataset classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                             return_indices=self.return_indices)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "white99 = white.copy()\n",
    "white_result = trick99(white99, 'hourglass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029ee70-e801-48af-b915-6b28c073b091",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd654612-6bf5-43ce-88cc-d9ae62cf36d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4435ae-c92d-4958-82a8-09f17b7e265b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hue_dict = {'red':(255,0,0),\n",
    " 'yellow': (255,255,0),\n",
    " 'pink': (255,0,255),\n",
    " 'green': (0,255,0),\n",
    " 'orange': (255,128,0),\n",
    " 'purple': (127,0,255),\n",
    " 'blue': (0,0,255),\n",
    " 'brown': (102,51,0),\n",
    " 'grey': (128,128,128),\n",
    " 'white': (255,255,255),\n",
    " 'black': (0,0,0)}\n",
    "\n",
    "step_weight = 0.5\n",
    "min_width_weight=20\n",
    "max_width_weight=100\n",
    "\n",
    "LIKENESS_TARGET = 96\n",
    "\n",
    "def placeRandCircle(image_param,color):\n",
    "    \n",
    "    min_width = min_width_weight\n",
    "    max_width = max_width_weight\n",
    "    size_rand = random.randint(min_width, max_width)\n",
    "\n",
    "    \n",
    "    x_rand = random.randint(0, 255-size_rand)\n",
    "    y_rand = random.randint(0,255-size_rand)\n",
    "\n",
    "    r_rand = random.randint(0, 255)\n",
    "    g_rand = random.randint(0, 255)\n",
    "    b_rand = random.randint(0, 255)\n",
    "\n",
    "    from PIL import Image, ImageDraw\n",
    "    draw = ImageDraw.Draw(image_param)\n",
    "\n",
    "    draw.ellipse((x_rand, y_rand, x_rand+size_rand, y_rand+size_rand), fill=color)\n",
    "    \n",
    "\n",
    "def genImage(image_param, item_param):\n",
    "    k=0\n",
    "    place_count=0\n",
    "    item=item_param\n",
    "\n",
    "    prev_image = image_param\n",
    "    prev_image_value = dict(pred(prev_image))[item]\n",
    "    \n",
    "    while(prev_image_value<LIKENESS_TARGET):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "        add_red_image = prev_image.copy()\n",
    "        placeRandCircle(add_red_image,hue_dict['red'])\n",
    "        add_red_image_value = dict(pred(add_red_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_red_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_red_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_red_image_value)\n",
    "            prev_image_value = add_red_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "\n",
    "        add_yellow_image = prev_image.copy()\n",
    "        placeRandCircle(add_yellow_image,hue_dict['yellow'])\n",
    "        add_yellow_image_value = dict(pred(add_yellow_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_yellow_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_yellow_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_yellow_image_value)\n",
    "            prev_image_value = add_yellow_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "\n",
    "        add_pink_image = prev_image.copy()\n",
    "        placeRandCircle(add_pink_image,hue_dict['pink'])\n",
    "        add_pink_image_value = dict(pred(add_pink_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_pink_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_pink_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_pink_image_value)\n",
    "            prev_image_value = add_pink_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "\n",
    "        add_green_image = prev_image.copy()\n",
    "        placeRandCircle(add_green_image,hue_dict['green'])\n",
    "        add_green_image_value = dict(pred(add_green_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_green_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_green_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_green_image_value)\n",
    "            prev_image_value = add_green_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_orange_image = prev_image.copy()\n",
    "        placeRandCircle(add_orange_image,hue_dict['orange'])\n",
    "        add_orange_image_value = dict(pred(add_orange_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_orange_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_orange_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_orange_image_value)\n",
    "            prev_image_value = add_orange_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_purple_image = prev_image.copy()\n",
    "        placeRandCircle(add_purple_image,hue_dict['purple'])\n",
    "        add_purple_image_value = dict(pred(add_purple_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_purple_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_purple_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_purple_image_value)\n",
    "            prev_image_value = add_purple_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_blue_image = prev_image.copy()\n",
    "        placeRandCircle(add_blue_image,hue_dict['blue'])\n",
    "        add_blue_image_value = dict(pred(add_blue_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_blue_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_blue_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_blue_image_value)\n",
    "            prev_image_value = add_blue_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_brown_image = prev_image.copy()\n",
    "        placeRandCircle(add_brown_image,hue_dict['brown'])\n",
    "        add_brown_image_value = dict(pred(add_brown_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_brown_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_brown_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_brown_image_value)\n",
    "            prev_image_value = add_brown_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_grey_image = prev_image.copy()\n",
    "        placeRandCircle(add_grey_image,hue_dict['grey'])\n",
    "        add_grey_image_value = dict(pred(add_grey_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_grey_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_grey_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_grey_image_value)\n",
    "            prev_image_value = add_grey_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_white_image = prev_image.copy()\n",
    "        placeRandCircle(add_white_image,hue_dict['white'])\n",
    "        add_white_image_value = dict(pred(add_white_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_white_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_white_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_white_image_value)\n",
    "            prev_image_value = add_white_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "            \n",
    "        add_black_image = prev_image.copy()\n",
    "        placeRandCircle(add_black_image,hue_dict['black'])\n",
    "        add_black_image_value = dict(pred(add_black_image))[item]\n",
    "        place_count+=1\n",
    "        if (add_black_image_value > prev_image_value+step_weight):\n",
    "            prev_image = add_black_image.copy()\n",
    "            print(f'Attempt:{place_count} Placement:{k} prev:',prev_image_value, 'current:', add_black_image_value)\n",
    "            prev_image_value = add_black_image_value\n",
    "            k=k+1\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    print(f'Finished - After {k} changes')\n",
    "    return ([pred(image_param),pred(prev_image),prev_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02512e70-60d3-4f62-9545-0ce5811fcbee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt:2459 Placement:16 prev: 94.90644073486328 current: 96.3474349975586\n",
      "Finished - After 17 changes\n"
     ]
    }
   ],
   "source": [
    "result2 = genImage(white.copy(),'acorn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7f43ee-276d-438f-b87b-b78c2fdbcd68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FAE50DB9EE0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e975a8-e8c5-4def-a014-209f508b55ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('corkscrew', 1.8588545322418213),\n",
       " ('hook', 1.1945443153381348),\n",
       " ('hair slide', 1.153014063835144),\n",
       " ('nail', 1.1527196168899536),\n",
       " ('whistle', 1.0341063737869263)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1426d641-ad25-4858-a1cd-d9090107aa64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test=white.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "850c840d-7203-4269-9b3f-fad1d4dca1ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "placeRandCircle(test,'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcbe3998-396d-4dad-9120-35f6940e64e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = np.asarray(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edbd8fa1-2aab-486a-9b2d-42d95d1e179e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3698391-fc8a-431c-931b-8978894fc6de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ideas\n",
    "<br>- Count what colors and sizes using in plots - once it gets to 25% restart with most common color-size weights increased proba\n",
    "<br>- use k counter to nudge out of a local minimum - create thick white border around edge of image to nudge along\n",
    "<br>- total pixel value count - if less than 1/4 of pixels != 255,255,255 at 25% restart process (avoids creating small objects/ noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6101ebae-f27a-4bf6-a036-bd38df4daa19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50135040"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*256*(255*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09a1bad6-1e66-4994-a99c-ea0d55ca4c73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46682850"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a398a0-490a-4ef9-b205-403a324362ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3acad-e546-43ad-a557-f17975289046",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9998d10-ba5c-450d-b762-f19efb42081b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5625b81-9492-4f86-8af3-84b50cd31cd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = [[1,0,0,0,0,0],\n",
    "         [0,1,0,1,1,1],\n",
    "         [0,0,1,0,1,0],\n",
    "         [1,1,0,0,1,0],\n",
    "         [1,0,1,1,0,0],\n",
    "         [1,0,0,0,0,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a028f217-6a86-4600-96a9-02fdd3366f07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in range(0,len(image)):\n",
    "    for column in image[row]:\n",
    "        print(column)c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7dfc2-0a2a-41c2-b93c-65f0c74a4026",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65886b6-8325-4d15-b04b-04bcb729c5f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74292430-326c-447f-a301-9f9bc19da6b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1127ae-eef3-4499-9600-32ae8e75e624",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b5e1a-39c4-4f9d-bd65-ee8fc6720db9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envAltair",
   "language": "python",
   "name": "envaltair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
